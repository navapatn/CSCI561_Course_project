# -*- coding: utf-8 -*-
"""HW3 MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16nM6uMxeSs6SlsYK5-_DJ_QHi1Qg4ii1
"""

import pickle
import gzip
import numpy as np
from google.colab import drive
drive.mount('/content/drive')

def load_data():
    f = gzip.open('/content/drive/MyDrive/HW3 data/mnist.pkl.gz', 'rb')
    training_data, validation_data, test_data = pickle.load(f, encoding="latin1")
    f.close()
    return (training_data, validation_data, test_data)
def load_data_wrapper():
    tr_d, va_d, te_d = load_data()
    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]
    training_results = [vectorized_result(y) for y in tr_d[1]]
    training_data = zip(training_inputs, training_results)
    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]
    validation_data = zip(validation_inputs, va_d[1])
    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]
    test_data = zip(test_inputs, te_d[1])
    return (training_data, validation_data, test_data)

def vectorized_result(j):
    e = np.zeros((10, 1))
    e[j] = 1.0
    return e

training_data, validation_data, test_data=load_data()
training_img=np.int32(training_data[0]*256)
training_label=np.int32(training_data[1])
validation_img = np.int32(validation_data[0]*256)
validation_label=np.int32(validation_data[1])
test_img=np.int32(test_data[0]*256)
test_label=np.int32(test_data[1])

tr_img = np.concatenate((training_img,validation_img))
tr_label = np.concatenate((training_label,validation_label))

tr_label=np.reshape(tr_label,(60000,1))
test_label=np.reshape(test_label,(10000,1))

np.savetxt('train_label.csv',tr_label,delimiter=',', fmt='%d')
np.savetxt('test_label.csv',test_label,delimiter=',', fmt='%d')
np.savetxt('train_image.csv',tr_img,delimiter=',', fmt='%d')
np.savetxt('test_image.csv',test_img,delimiter=',', fmt='%d')

from google.colab import drive
drive.mount('/content/drive')

"""

```
# This is formatted as code
```

# Reading CSV files"""

import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import math
import matplotlib.cm as cm 
import matplotlib.pyplot as plt

train_data_csv = pd.read_csv("train_image.csv")
test_data_csv =  pd.read_csv("test_image.csv")
#separating labels and pixels
train_labels_csv= pd.read_csv("train_label.csv")
test_labels_csv= pd.read_csv("test_label.csv")


# merge labels with actual pixels data
train_data = train_labels_csv.join(train_data_csv)
test_data = test_labels_csv.join(test_data_csv)

train_data_merged = np.array(train_data)
test_data_merged = np.array(test_data)



## shuffle train set and test set
#np.take(train_data_merged,np.random.rand(train_data_merged.shape[0]).argsort(),axis=0,out=train_data_merged)
#np.take(test_data_merged,np.random.rand(test_data_merged.shape[0]).argsort(),axis=0,out=test_data_merged)




train_data_merged_sliced = train_data_merged[0:10000]
test_data_merged_sliced = test_data_merged[0:10000]


def load_data(data):
    def one_hot(y):
        table = np.zeros((y.shape[0], 10))
        for i in range(y.shape[0]):
            table[i][int(y[i][0])] = 1 
        return table

    def normalize(x): 
        x = x / 255
        return x 

    #data = np.loadtxt('{}'.format(path), delimiter = ',')
    return normalize(data[:,1:]),one_hot(data[:,:1])
#train_data=np.array(train_data.loc[:,train_data.columns!='label'])
#train_data=train_data/train_data.max()

X_train, y_train = load_data(train_data_merged_sliced)
X_test, y_test = load_data(test_data_merged_sliced)

"""# Analysing Input data"""

# #Visualize the input data. Change the index value to visualize the particular index data.
# index = 9
# plt.title((train_labels[index]))
# plt.imshow(train_data[index].reshape(28,28), cmap=cm.binary)

# print("train data")
# y_value=np.zeros((1,10))
# for i in range (10):
#     print("occurance of ",i,"=",np.count_nonzero(train_labels==i))
#     y_value[0,i-1]= np.count_nonzero(train_labels==i)

"""# Neural Network"""

class NeuralNetwork:
    def __init__(self, X, y, batch = 16, lr = 1e-1,  epochs = 300):
      #### 60000
      ## batch = 64, lr = 5e-2,  epochs =  200  94% acc   
      ##  batch = 64, lr = 1e-1,  epochs =  200 94.68% acc
      ##  batch = 64, lr = 1e-1,  epochs =  200 95.11% acc
       ##  batch = 64, lr = 1e-1,  epochs =  200 94.68% acc
       ##### 10000 training set
       ## batch = 32, lr = 1e-1, epochs = 500   90.37%
       ## batch = 32, lr = 1e-1,  epochs =  300  90.76%
       ##  batch = 32, lr = 1e-2,  epochs =  500  88.85%
       ## batch = 32, lr = 1e-2,  epochs =  1000 89.81%
       ## batch = 16, lr = 1e-2,  epochs =  1000  90.17%
       ## batch = 16, lr = 1e-1,  epochs =  1000  91.44 %
       ## batch = 16, lr = 1e-1,  epochs = 300  90.85%
       ##  batch = 16, lr = 1e-1,  epochs = 300 91.2%


        self.input = X 
        self.target = y
        self.batch = batch
        self.epochs = epochs
        self.lr = lr
        
        self.x = self.input[:self.batch] # batch input 
        self.y = self.target[:self.batch] # batch target value
        self.loss = []
        self.acc = []
        
        self.init_weights()
      
    def init_weights(self):
        self.W1 = np.random.randn(self.input.shape[1],128)
        self.W2 = np.random.randn(self.W1.shape[1],64)
        self.W3 = np.random.randn(self.W2.shape[1],self.y.shape[1])

        self.b1 = np.random.randn(self.W1.shape[1],)
        self.b2 = np.random.randn(self.W2.shape[1],)
        self.b3 = np.random.randn(self.W3.shape[1],)
    
    def sigmoid(self, x, derivative = False):
        if derivative:
          return (np.exp(-x))/((np.exp(-x)+1)**2)
        return 1/(1 + np.exp(-x))

    def ReLU(self, x):
        return np.maximum(0,x)

    def dReLU(self,x):
        return 1 * (x > 0) 
    
    def softmax(self, z):
        z = z - np.max(z, axis = 1).reshape(z.shape[0],1)
        return np.exp(z) / np.sum(np.exp(z), axis = 1).reshape(z.shape[0],1)
    
    def shuffle(self):
        idx = [i for i in range(self.input.shape[0])]
        np.random.shuffle(idx)
        self.input = self.input[idx]
        self.target = self.target[idx]
        
    def feedforward(self):
        assert self.x.shape[1] == self.W1.shape[0]
        self.z1 = self.x.dot(self.W1) + self.b1
        self.a1 = self.sigmoid(self.z1)

        assert self.a1.shape[1] == self.W2.shape[0]
        self.z2 = self.a1.dot(self.W2) + self.b2
        self.a2 = self.sigmoid(self.z2)

        assert self.a2.shape[1] == self.W3.shape[0]
        self.z3 = self.a2.dot(self.W3) + self.b3
        self.a3 = self.softmax(self.z3)
        self.error = self.a3 - self.y

        
    def backprop(self):
        dcost = (1/self.batch)*self.error
        
        DW3 = np.dot(dcost.T,self.a2).T
        DW2 = np.dot((np.dot((dcost),self.W3.T) * self.sigmoid(self.z2, derivative = True)).T,self.a1).T
        DW1 = np.dot((np.dot(np.dot((dcost),self.W3.T)*self.sigmoid(self.z2, derivative = True),self.W2.T)*self.sigmoid(self.z1, derivative = True)).T,self.x).T

        db3 = np.sum(dcost,axis = 0)
        db2 = np.sum(np.dot((dcost),self.W3.T) * self.sigmoid(self.z2 , derivative = True),axis = 0)
        db1 = np.sum((np.dot(np.dot((dcost),self.W3.T)*self.sigmoid(self.z2, derivative = True),self.W2.T)*self.sigmoid(self.z1, derivative = True)),axis = 0)
        
        assert DW3.shape == self.W3.shape
        assert DW2.shape == self.W2.shape
        assert DW1.shape == self.W1.shape
        
        assert db3.shape == self.b3.shape
        assert db2.shape == self.b2.shape
        assert db1.shape == self.b1.shape 
        
        self.W3 = self.W3 - self.lr * DW3
        self.W2 = self.W2 - self.lr * DW2
        self.W1 = self.W1 - self.lr * DW1
        
        self.b3 = self.b3 - self.lr * db3
        self.b2 = self.b2 - self.lr * db2
        self.b1 = self.b1 - self.lr * db1

    def train(self):
        for epoch in range(self.epochs):
            l = 0
            acc = 0
            self.shuffle()
            
            for batch in range(self.input.shape[0]//self.batch-1):
                start = batch*self.batch
                end = (batch+1)*self.batch
                self.x = self.input[start:end]
                self.y = self.target[start:end]
                self.feedforward()
                self.backprop()
                l+=np.mean(self.error**2)
                acc+= np.count_nonzero(np.argmax(self.a3,axis=1) == np.argmax(self.y,axis=1)) / self.batch
                
            self.loss.append(l/(self.input.shape[0]//self.batch))
            self.acc.append(acc*100/(self.input.shape[0]//self.batch))
            
    def plot(self):
        plt.figure(dpi = 125)
        plt.plot(self.loss)
        plt.xlabel("Epochs")
        plt.ylabel("Loss")
    
    def acc_plot(self):
        plt.figure(dpi = 125)
        plt.plot(self.acc)
        plt.xlabel("Epochs")
        plt.ylabel("Accuracy")
        
    def test(self,xtest,ytest):
        self.x = xtest
        self.y = ytest
        self.feedforward()
        predict_array = np.argmax(self.a3,axis=1)
        predict_array = predict_array.astype(int)
        acc = np.count_nonzero(np.argmax(self.a3,axis=1) == np.argmax(self.y,axis=1)) / self.x.shape[0]
        np.savetxt("test_predictions.csv", predict_array , delimiter=",")
        print("Accuracy:", 100 * acc, "%")
    
        
        
NN = NeuralNetwork(X_train, y_train) 
NN.train()
NN.plot()
NN.test(X_test,y_test)